import numpy as np
import pandas as pd
from nilearn.image import new_img_like, load_img, get_data
from nilearn.image import resample_to_img
from sklearn.model_selection import KFold
from nilearn.image import index_img
import nilearn.decoding
from nilearn.input_data import NiftiMasker
import nilearn as nil
import nibabel as nib
import copy
from sklearn.model_selection import StratifiedKFold
from sklearn.svm import LinearSVC
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from nilearn.masking import intersect_masks
from joblib import Parallel, delayed
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import joblib
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve, average_precision_score 
from nilearn import plotting
from sklearn.metrics import confusion_matrix
from nilearn.connectome import ConnectivityMeasure
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import LogisticRegression
from nilearn.datasets import load_mni152_template
from sklearn.ensemble import RandomForestClassifier
import warnings
import time
from nilearn import datasets
from nilearn.input_data import NiftiLabelsMasker

aal_atlas = datasets.fetch_atlas_aal()
masker = NiftiLabelsMasker(labels_img=aal_atlas.maps, standardize=True,
                           memory='nilearn_cache', verbose=5, resampling_target = 'labels')
filename = pd.read_csv('/links/groups/borgwardt/Projects/ZhiYe_MasterThesis/modality/MD_HC_T1.csv', dtype = str)

mri = []
for i in range(0, filename.shape[0]):
   start_time = time.time()
   mri.append(masker.fit_transform(filename['file'].loc[i]))
   print(i)
   print(mri[i].shape)
   print(time.time() - start_time)

mri = np.reshape(np.array(mri), (-1, mri[0].shape[1]))
np.save('/links/groups/borgwardt/Projects/ZhiYe_MasterThesis/T1_ROI.npy', mri)

accuracy = []
f1 = []
recall = []
precision_plot = []
recall_plot = []
precision = []
spcificty = []
tprs = []
fprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)
AUROC = []
AUPR = []
y_true = []
y_proba = []

model = base_model
outer_cv = StratifiedKFold(n_splits = cv_fold, shuffle = True, random_state = i)
inner_cv = StratifiedKFold(n_splits = cv_fold, shuffle = True, random_state = i)

#run outter CV to evaluate model
for j, (train, test) in enumerate(outer_cv.split(X, y)):
    #split dataset to decoding set and test set
    x_train, x_test = X[train], X[test]
    y_train, y_test = y[train], y[test]
    #find optim paramater setting in the inner cv
    clf = GridSearchCV(estimator = model, param_grid = p_grid, cv = inner_cv, scoring = "recall")
    clf.fit(x_train, y_train)

    #predict labels on the test set
    y_pred = clf.predict(x_test)
    #calculate metrics
    a = metrics.accuracy_score(y_test, y_pred)
    f = metrics.f1_score(y_test, y_pred)
    r = metrics.recall_score(y_test, y_pred, average='binary')
    p = metrics.precision_score(y_test, y_pred, average='binary')
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    s = tn / (tn+fp)
    accuracy.append(a)
    f1.append(f)
    recall.append(r)
    precision.append(p)
    spcificty.append(s)
    y_score = clf.predict_proba(x_test)[:,1]
    pre, re, thresholds = precision_recall_curve(y_test, y_score)
    AUPR.append(auc(re, pre))
    fpr, tpr, thresholds = roc_curve(y_test, y_score)
    AUROC.append(auc(fpr, tpr))
